#!/usr/bin/env python3
"""
Data Cleaning & Preprocessing for Danang Real Estate Database
Senior Data Engineer Approach
"""

import sqlite3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import re
from typing import Tuple, List, Dict
import warnings
warnings.filterwarnings('ignore')

# Set Vietnamese locale for better display
plt.rcParams['font.family'] = ['DejaVu Sans']
sns.set_style("whitegrid")

class DanangRealEstateCleaner:
    def __init__(self, db_path: str):
        """Initialize the data cleaner with database path"""
        self.db_path = db_path
        self.df = None
        self.original_shape = None
        
    def load_data(self) -> pd.DataFrame:
        """Load data from SQLite database"""
        print("=== 1. KH·∫¢O S√ÅT S∆† B·ªò (DATA PROFILING) ===")
        
        conn = sqlite3.connect(self.db_path)
        query = "SELECT * FROM danang_batdongsan"
        self.df = pd.read_sql_query(query, conn)
        conn.close()
        
        self.original_shape = self.df.shape
        print(f"‚úì ƒê√£ t·∫£i {self.original_shape[0]} b·∫£n ghi v·ªõi {self.original_shape[1]} c·ªôt")
        
        return self.df
    
    def data_profiling(self):
        """Step 1: Kh·∫£o s√°t s∆° b·ªô d·ªØ li·ªáu"""
        print("\n--- 1.1. Th·ªëng k√™ c∆° b·∫£n ---")
        print(f"T·ªïng s·ªë b·∫£n ghi: {len(self.df):,}")
        print(f"S·ªë c·ªôt: {len(self.df.columns)}")
        
        # Ki·ªÉm tra null values
        print("\n--- 1.2. Ki·ªÉm tra gi√° tr·ªã null ---")
        null_counts = self.df.isnull().sum()
        null_percentages = (null_counts / len(self.df)) * 100
        
        null_summary = pd.DataFrame({
            'Null Count': null_counts,
            'Null Percentage': null_percentages
        })
        print(null_summary[null_summary['Null Count'] > 0])
        
        # Ph√¢n t√≠ch c√°c c·ªôt s·ªë
        numeric_cols = ['price', 'area', 'bedrooms', 'bathrooms']
        print(f"\n--- 1.3. Ph√¢n t√≠ch c·ªôt s·ªë: {numeric_cols} ---")
        
        for col in numeric_cols:
            if col in self.df.columns:
                print(f"\n{col.upper()}:")
                print(f"  - Min: {self.df[col].min():,.0f}")
                print(f"  - Max: {self.df[col].max():,.0f}")
                print(f"  - Mean: {self.df[col].mean():,.2f}")
                print(f"  - Median: {self.df[col].median():,.2f}")
                print(f"  - Std: {self.df[col].std():,.2f}")
                
                # Ki·ªÉm tra gi√° tr·ªã 0 v√† √¢m
                zero_count = (self.df[col] == 0).sum()
                negative_count = (self.df[col] < 0).sum()
                print(f"  - Gi√° tr·ªã = 0: {zero_count}")
                print(f"  - Gi√° tr·ªã < 0: {negative_count}")
        
        # Ph√¢n t√≠ch outliers b·∫±ng IQR
        self._analyze_outliers()
        
    def _analyze_outliers(self):
        """Ph√¢n t√≠ch outliers s·ª≠ d·ª•ng IQR method"""
        print("\n--- 1.4. Ph√¢n t√≠ch Outliers (IQR Method) ---")
        
        numeric_cols = ['price', 'area', 'bedrooms', 'bathrooms']
        
        for col in numeric_cols:
            if col in self.df.columns:
                Q1 = self.df[col].quantile(0.25)
                Q3 = self.df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)]
                outlier_count = len(outliers)
                outlier_percentage = (outlier_count / len(self.df)) * 100
                
                print(f"\n{col.upper()}:")
                print(f"  - Q1: {Q1:,.2f}")
                print(f"  - Q3: {Q3:,.2f}")
                print(f"  - IQR: {IQR:,.2f}")
                print(f"  - Lower bound: {lower_bound:,.2f}")
                print(f"  - Upper bound: {upper_bound:,.2f}")
                print(f"  - Outliers: {outlier_count} ({outlier_percentage:.2f}%)")
    
    def handle_missing_invalid_data(self):
        """Step 2: X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu/kh√¥ng h·ª£p l·ªá"""
        print("\n=== 2. X·ª¨ L√ù D·ªÆ LI·ªÜU THI·∫æU / KH√îNG H·ª¢P L·ªÜ ===")
        
        # L∆∞u tr·∫°ng th√°i ban ƒë·∫ßu
        initial_count = len(self.df)
        
        # 2.1. X·ª≠ l√Ω gi√° tr·ªã null/empty cho t·∫•t c·∫£ c√°c c·ªôt
        print("\n--- 2.1. X·ª≠ l√Ω gi√° tr·ªã null/empty ---")
        
        # Thay th·∫ø null v√† empty values b·∫±ng "N/A"
        for col in self.df.columns:
            if self.df[col].dtype == 'object':  # Text columns
                # Thay th·∫ø null v√† empty strings b·∫±ng "N/A"
                self.df[col] = self.df[col].fillna("N/A")
                self.df[col] = self.df[col].replace('', "N/A")
                self.df[col] = self.df[col].replace('nan', "N/A")
                self.df[col] = self.df[col].replace('None', "N/A")
            else:  # Numeric columns
                # Gi·ªØ nguy√™n gi√° tr·ªã null cho numeric columns
                self.df[col] = self.df[col].fillna(0)
                self.df[col] = self.df[col].replace('', 0)
                self.df[col] = self.df[col].replace('nan', 0)
                self.df[col] = self.df[col].replace('None', 0)
        
        # 2.2. X·ª≠ l√Ω gi√° tr·ªã 0 (kh√¥ng lo·∫°i b·ªè gi√° tr·ªã √¢m)
        print("\n--- 2.2. X·ª≠ l√Ω gi√° tr·ªã 0 (gi·ªØ nguy√™n gi√° tr·ªã √¢m) ---")
        
        # Ch·ªâ x·ª≠ l√Ω gi√° tr·ªã = 0, gi·ªØ nguy√™n gi√° tr·ªã √¢m
        for col in ['price', 'area']:
            if col in self.df.columns:
                zero_count = (self.df[col] == 0).sum()
                negative_count = (self.df[col] < 0).sum()
                if zero_count > 0:
                    print(f"  - {col}: {zero_count} gi√° tr·ªã = 0 ‚Üí Thay th·∫ø b·∫±ng NaN")
                    self.df[col] = self.df[col].replace(0, np.nan)
                if negative_count > 0:
                    print(f"  - {col}: {negative_count} gi√° tr·ªã √¢m ‚Üí Gi·ªØ nguy√™n")
        
        # Bedrooms v√† bathrooms - gi·ªØ nguy√™n gi√° tr·ªã √¢m
        for col in ['bedrooms', 'bathrooms']:
            if col in self.df.columns:
                negative_count = (self.df[col] < 0).sum()
                if negative_count > 0:
                    print(f"  - {col}: {negative_count} gi√° tr·ªã √¢m ‚Üí Gi·ªØ nguy√™n")
        
        # 2.3. Chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu
        print("\n--- 2.3. Chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu ---")
        
        # Chuy·ªÉn posted_time t·ª´ TEXT sang datetime
        if 'posted_time' in self.df.columns:
            print("  - Chuy·ªÉn posted_time t·ª´ TEXT sang datetime")
            # Ch·ªâ x·ª≠ l√Ω c√°c gi√° tr·ªã kh√¥ng ph·∫£i "N/A"
            mask = self.df['posted_time'] != "N/A"
            self.df.loc[mask, 'posted_time'] = pd.to_datetime(
                self.df.loc[mask, 'posted_time'], 
                format='%d-%m-%Y', 
                errors='coerce'
            )
            # Thay th·∫ø c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá b·∫±ng "N/A"
            invalid_dates = self.df['posted_time'].isnull().sum()
            if invalid_dates > 0:
                print(f"    ‚Üí Thay th·∫ø {invalid_dates} b·∫£n ghi c√≥ ng√†y kh√¥ng h·ª£p l·ªá b·∫±ng 'N/A'")
                self.df['posted_time'] = self.df['posted_time'].fillna("N/A")
        
        # Chuy·ªÉn is_selling t·ª´ BOOLEAN sang INTEGER
        if 'is_selling' in self.df.columns:
            print("  - Chuy·ªÉn is_selling sang INTEGER (0/1)")
            # Ch·ªâ x·ª≠ l√Ω c√°c gi√° tr·ªã h·ª£p l·ªá
            mask = self.df['is_selling'].notna()
            self.df.loc[mask, 'is_selling'] = self.df.loc[mask, 'is_selling'].astype(int)
        
        # 2.4. T√°ch c·ªôt coordinates
        if 'coordinates' in self.df.columns:
            print("  - T√°ch c·ªôt coordinates th√†nh latitude v√† longitude")
            # Ch·ªâ x·ª≠ l√Ω c√°c gi√° tr·ªã kh√¥ng ph·∫£i "N/A"
            mask = self.df['coordinates'] != "N/A"
            coords_data = self.df.loc[mask, 'coordinates'].str.extract(r'([\d.-]+),([\d.-]+)')
            
            # Kh·ªüi t·∫°o c·ªôt latitude v√† longitude v·ªõi "N/A"
            self.df['latitude'] = "N/A"
            self.df['longitude'] = "N/A"
            
            # C·∫≠p nh·∫≠t c√°c gi√° tr·ªã h·ª£p l·ªá
            if not coords_data.empty:
                self.df.loc[mask, 'latitude'] = pd.to_numeric(coords_data[0], errors='coerce')
                self.df.loc[mask, 'longitude'] = pd.to_numeric(coords_data[1], errors='coerce')
                
                # Thay th·∫ø c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá b·∫±ng "N/A"
                invalid_coords = self.df.loc[mask, 'latitude'].isnull().sum()
                if invalid_coords > 0:
                    print(f"    ‚Üí Thay th·∫ø {invalid_coords} b·∫£n ghi c√≥ t·ªça ƒë·ªô kh√¥ng h·ª£p l·ªá b·∫±ng 'N/A'")
                    self.df.loc[mask, 'latitude'] = self.df.loc[mask, 'latitude'].fillna("N/A")
                    self.df.loc[mask, 'longitude'] = self.df.loc[mask, 'longitude'].fillna("N/A")
        
        print(f"\n‚úì ƒê√£ x·ª≠ l√Ω: {initial_count - len(self.df)} b·∫£n ghi b·ªã lo·∫°i b·ªè")
        print(f"‚úì C√≤n l·∫°i: {len(self.df)} b·∫£n ghi")
    
    def normalize_address_fields(self):
        """Step 3: Chu·∫©n h√≥a tr∆∞·ªùng ƒë·ªãa ch·ªâ"""
        print("\n=== 3. CHU·∫®N H√ìA TR∆Ø·ªúNG ƒê·ªäA CH·ªà ===")
        
        # 3.1. Lo·∫°i b·ªè kho·∫£ng tr·∫Øng d∆∞ th·ª´a v√† chu·∫©n h√≥a ch·ªØ hoa/th∆∞·ªùng
        address_cols = ['location', 'street', 'ward', 'district', 'city']
        
        for col in address_cols:
            if col in self.df.columns:
                print(f"  - Chu·∫©n h√≥a {col}")
                # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng d∆∞ th·ª´a
                self.df[col] = self.df[col].str.strip()
                # Chu·∫©n h√≥a ch·ªØ hoa/th∆∞·ªùng
                self.df[col] = self.df[col].str.title()
        
        # 3.2. Chu·∫©n h√≥a t√™n qu·∫≠n/huy·ªán
        print("  - Chu·∫©n h√≥a t√™n qu·∫≠n/huy·ªán")
        
        # Lo·∫°i b·ªè ti·ªÅn t·ªë Qu·∫≠n/Huy·ªán ·ªü ƒë·∫ßu chu·ªói: "Qu·∫≠n ", "Huy·ªán ", "Q.", "H." (kh√¥ng ·∫£nh h∆∞·ªüng v·ªã tr√≠ kh√°c)
        self.df['district'] = self.df['district'].astype(str).str.strip()
        self.df['district'] = self.df['district'].str.replace(r'^\s*(Qu·∫≠n|Huy·ªán)\s+', '', regex=True)
        self.df['district'] = self.df['district'].str.replace(r'^\s*(Q\.|H\.)\s*', '', regex=True)
        # Chu·∫©n h√≥a l·∫°i kho·∫£ng tr·∫Øng v√† ch·ªØ hoa/th∆∞·ªùng sau khi thay th·∫ø
        self.df['district'] = self.df['district'].str.strip().str.title()

        # 3.3. Chu·∫©n h√≥a t√™n ph∆∞·ªùng
        print("  - Chu·∫©n h√≥a t√™n ph∆∞·ªùng")
        
        # Lo·∫°i b·ªè t·ª´ "Ph∆∞·ªùng" v√† chu·∫©n h√≥a
        self.df['ward'] = self.df['ward'].str.replace('Ph∆∞·ªùng ', '', regex=False)
        self.df['ward'] = self.df['ward'].str.replace('P.', '', regex=False)
        
        print("‚úì Ho√†n th√†nh chu·∫©n h√≥a ƒë·ªãa ch·ªâ")
    
    def remove_duplicates(self):
        """Step 4: Lo·∫°i b·ªè b·∫£n ghi tr√πng l·∫∑p"""
        print("\n=== 4. LO·∫†I B·ªé B·∫¢N GHI TR√ôNG L·∫∂P ===")
        
        initial_count = len(self.df)
        
        # 4.1. Ki·ªÉm tra tr√πng l·∫∑p d·ª±a tr√™n property_code
        if 'property_code' in self.df.columns:
            duplicates_by_code = self.df.duplicated(subset=['property_code'], keep=False)
            duplicate_count = duplicates_by_code.sum()
            print(f"  - Tr√πng l·∫∑p theo property_code: {duplicate_count} b·∫£n ghi")
            
            if duplicate_count > 0:
                # Gi·ªØ l·∫°i b·∫£n ghi c√≥ √≠t null nh·∫•t
                self.df = self.df.sort_values('property_code').drop_duplicates(
                    subset=['property_code'], 
                    keep='first'
                )
        
        # 4.2. Ki·ªÉm tra tr√πng l·∫∑p d·ª±a tr√™n t·ªï h·ª£p (title + street + posted_time)
        duplicate_cols = ['title', 'street', 'posted_time']
        if all(col in self.df.columns for col in duplicate_cols):
            duplicates_by_combination = self.df.duplicated(subset=duplicate_cols, keep=False)
            duplicate_count = duplicates_by_combination.sum()
            print(f"  - Tr√πng l·∫∑p theo t·ªï h·ª£p (title + street + posted_time): {duplicate_count} b·∫£n ghi")
            
            if duplicate_count > 0:
                # Gi·ªØ l·∫°i b·∫£n ghi c√≥ √≠t null nh·∫•t
                self.df = self.df.sort_values(duplicate_cols).drop_duplicates(
                    subset=duplicate_cols, 
                    keep='first'
                )
        
        final_count = len(self.df)
        removed_count = initial_count - final_count
        
        print(f"‚úì ƒê√£ lo·∫°i b·ªè {removed_count} b·∫£n ghi tr√πng l·∫∑p")
        print(f"‚úì C√≤n l·∫°i: {final_count} b·∫£n ghi")
    
    def handle_outliers_and_transformations(self):
        """Step 5: X·ª≠ l√Ω outlier & chuy·ªÉn ƒë·ªïi th√™m"""
        print("\n=== 5. X·ª¨ L√ù OUTLIER & CHUY·ªÇN ƒê·ªîI TH√äM ===")
        
        # 5.1. X√°c ƒë·ªãnh v√† x·ª≠ l√Ω outliers cho price v√† area (kh√¥ng lo·∫°i b·ªè gi√° tr·ªã √¢m)
        print("\n--- 5.1. X·ª≠ l√Ω outliers cho price v√† area (gi·ªØ nguy√™n gi√° tr·ªã √¢m) ---")
        
        for col in ['price', 'area']:
            if col in self.df.columns:
                # Ch·ªâ x·ª≠ l√Ω c√°c gi√° tr·ªã d∆∞∆°ng cho outlier detection
                positive_mask = self.df[col] > 0
                if positive_mask.sum() > 0:
                    positive_data = self.df.loc[positive_mask, col]
                    # S·ª≠ d·ª•ng percentile method (1% - 99%) ch·ªâ cho gi√° tr·ªã d∆∞∆°ng
                    lower_percentile = positive_data.quantile(0.01)
                    upper_percentile = positive_data.quantile(0.99)
                    
                    # Ch·ªâ x·ª≠ l√Ω outliers cho gi√° tr·ªã d∆∞∆°ng
                    outlier_mask = positive_mask & ((self.df[col] < lower_percentile) | (self.df[col] > upper_percentile))
                    outlier_count = outlier_mask.sum()
                    
                    print(f"  - {col}: {outlier_count} outliers d∆∞∆°ng (1%-99%: {lower_percentile:,.0f} - {upper_percentile:,.0f})")
                    
                    # Thay th·∫ø outliers b·∫±ng NaN thay v√¨ lo·∫°i b·ªè
                    self.df.loc[outlier_mask, col] = np.nan
                else:
                    print(f"  - {col}: Kh√¥ng c√≥ gi√° tr·ªã d∆∞∆°ng ƒë·ªÉ x·ª≠ l√Ω outliers")
        
        # 5.2. T·∫°o c·ªôt d·∫´n xu·∫•t
        print("\n--- 5.2. T·∫°o c·ªôt d·∫´n xu·∫•t ---")
        
        # Price per square meter (ch·ªâ t√≠nh cho gi√° tr·ªã d∆∞∆°ng)
        if all(col in self.df.columns for col in ['price', 'area']):
            # Ch·ªâ t√≠nh cho c√°c b·∫£n ghi c√≥ c·∫£ price v√† area > 0
            valid_mask = (self.df['price'] > 0) & (self.df['area'] > 0)
            self.df['price_per_sqm'] = np.nan
            self.df.loc[valid_mask, 'price_per_sqm'] = self.df.loc[valid_mask, 'price'] / self.df.loc[valid_mask, 'area']
            print("  - T·∫°o c·ªôt price_per_sqm (gi√°/m¬≤) - ch·ªâ cho gi√° tr·ªã d∆∞∆°ng")
        
        # Log transformation cho price v√† area (ch·ªâ cho gi√° tr·ªã d∆∞∆°ng)
        for col in ['price', 'area']:
            if col in self.df.columns:
                self.df[f'{col}_log'] = np.nan
                positive_mask = self.df[col] > 0
                if positive_mask.sum() > 0:
                    self.df.loc[positive_mask, f'{col}_log'] = np.log1p(self.df.loc[positive_mask, col])
                print(f"  - T·∫°o c·ªôt {col}_log (log transformation) - ch·ªâ cho gi√° tr·ªã d∆∞∆°ng")
        
        # 5.3. T·∫°o c·ªôt th·ªùi gian
        if 'posted_time' in self.df.columns:
            # Ch·ªâ x·ª≠ l√Ω cho c√°c gi√° tr·ªã datetime h·ª£p l·ªá
            datetime_mask = pd.to_datetime(self.df['posted_time'], errors='coerce').notna()
            self.df['posted_year'] = "N/A"
            self.df['posted_month'] = "N/A"
            self.df['posted_day'] = "N/A"
            
            if datetime_mask.sum() > 0:
                posted_time_dt = pd.to_datetime(self.df.loc[datetime_mask, 'posted_time'])
                self.df.loc[datetime_mask, 'posted_year'] = posted_time_dt.dt.year
                self.df.loc[datetime_mask, 'posted_month'] = posted_time_dt.dt.month
                self.df.loc[datetime_mask, 'posted_day'] = posted_time_dt.dt.day
            print("  - T·∫°o c·ªôt th·ªùi gian (year, month, day) - ch·ªâ cho ng√†y h·ª£p l·ªá")
        
        print("‚úì Ho√†n th√†nh x·ª≠ l√Ω outliers v√† t·∫°o c·ªôt d·∫´n xu·∫•t")
        
        # 5.4. Chu·∫©n ho√° c√°c tr∆∞·ªùng d·∫´n xu·∫•t b·ªã null (gi·ªØ ki·ªÉu s·ªë)
        for col in ['price_per_sqm', 'price_log', 'area_log']:
            if col in self.df.columns:
                self.df[col] = pd.to_numeric(self.df[col], errors='coerce').fillna(0)
    
    def generate_cleaning_report(self):
        """T·∫°o b√°o c√°o t·ªïng h·ª£p v·ªÅ qu√° tr√¨nh cleaning"""
        print("\n" + "="*60)
        print("B√ÅO C√ÅO T·ªîNG H·ª¢P DATA CLEANING & PREPROCESSING")
        print("="*60)
        
        print(f"\nüìä TH·ªêNG K√ä T·ªîNG QUAN:")
        print(f"  - B·∫£n ghi ban ƒë·∫ßu: {self.original_shape[0]:,}")
        print(f"  - B·∫£n ghi sau cleaning: {len(self.df):,}")
        print(f"  - B·∫£n ghi b·ªã lo·∫°i b·ªè: {self.original_shape[0] - len(self.df):,}")
        print(f"  - T·ª∑ l·ªá gi·ªØ l·∫°i: {(len(self.df) / self.original_shape[0]) * 100:.2f}%")
        
        print(f"\nüìà TH·ªêNG K√ä SAU CLEANING:")
        numeric_cols = ['price', 'area', 'bedrooms', 'bathrooms']
        for col in numeric_cols:
            if col in self.df.columns:
                # Ch·ªâ t√≠nh th·ªëng k√™ cho c√°c gi√° tr·ªã s·ªë h·ª£p l·ªá
                numeric_data = pd.to_numeric(self.df[col], errors='coerce')
                valid_data = numeric_data.dropna()
                
                if len(valid_data) > 0:
                    print(f"  - {col}:")
                    print(f"    Min: {valid_data.min():,.0f}")
                    print(f"    Max: {valid_data.max():,.0f}")
                    print(f"    Mean: {valid_data.mean():,.2f}")
                    print(f"    Median: {valid_data.median():,.2f}")
                    print(f"    Valid records: {len(valid_data):,}")
                    print(f"    Invalid/NA records: {len(self.df) - len(valid_data):,}")
                else:
                    print(f"  - {col}: Kh√¥ng c√≥ gi√° tr·ªã s·ªë h·ª£p l·ªá")
        
        if 'price_per_sqm' in self.df.columns:
            # Ch·ªâ t√≠nh cho c√°c gi√° tr·ªã h·ª£p l·ªá
            price_per_sqm_numeric = pd.to_numeric(self.df['price_per_sqm'], errors='coerce')
            valid_price_per_sqm = price_per_sqm_numeric.dropna()
            
            if len(valid_price_per_sqm) > 0:
                print(f"\nüí∞ GI√Å TRUNG B√åNH:")
                print(f"  - Gi√°/m¬≤ (mean): {valid_price_per_sqm.mean():,.0f} VND/m¬≤")
                print(f"  - Gi√°/m¬≤ (median): {valid_price_per_sqm.median():,.0f} VND/m¬≤")
                print(f"  - Valid price/m¬≤ records: {len(valid_price_per_sqm):,}")
            else:
                print(f"\nüí∞ GI√Å TRUNG B√åNH: Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá")
        
        print(f"\nüó∫Ô∏è PH√ÇN B·ªê THEO QU·∫¨N:")
        if 'district' in self.df.columns:
            district_counts = self.df['district'].value_counts()
            for district, count in district_counts.head().items():
                print(f"  - {district}: {count:,} b·∫£n ghi")
        
        print("\n‚úÖ HO√ÄN TH√ÄNH DATA CLEANING & PREPROCESSING!")
    
    def save_cleaned_data(self, output_path: str = None):
        """L∆∞u d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c cleaning"""
        if output_path is None:
            output_path = "cleaned_danang_real_estate.csv"
        
        # T·∫°o b·∫£n sao ƒë·ªÉ x·ª≠ l√Ω datetime tr∆∞·ªõc khi l∆∞u
        df_to_save = self.df.copy()
        
        # Chuy·ªÉn ƒë·ªïi datetime th√†nh string ƒë·ªÉ l∆∞u v√†o CSV
        if 'posted_time' in df_to_save.columns:
            df_to_save['posted_time'] = df_to_save['posted_time'].astype(str)
        
        df_to_save.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nüíæ ƒê√£ l∆∞u d·ªØ li·ªáu ƒë√£ cleaning v√†o: {output_path}")
        
        # C≈©ng l∆∞u v√†o SQLite
        sqlite_output = output_path.replace('.csv', '.db')
        conn = sqlite3.connect(sqlite_output)
        
        # Chuy·ªÉn ƒë·ªïi datetime th√†nh string cho SQLite
        if 'posted_time' in df_to_save.columns:
            df_to_save['posted_time'] = df_to_save['posted_time'].replace('NaT', 'N/A')
        
        df_to_save.to_sql('cleaned_danang_batdongsan', conn, if_exists='replace', index=False)
        conn.close()
        print(f"üíæ ƒê√£ l∆∞u d·ªØ li·ªáu ƒë√£ cleaning v√†o SQLite: {sqlite_output}")
    
    def run_complete_cleaning(self):
        """Ch·∫°y to√†n b·ªô quy tr√¨nh cleaning"""
        # Load data
        self.load_data()
        
        # Step 1: Data profiling
        self.data_profiling()
        
        # Step 2: Handle missing/invalid data
        self.handle_missing_invalid_data()
        
        # Step 3: Normalize address fields
        self.normalize_address_fields()
        
        # Step 4: Remove duplicates
        self.remove_duplicates()
        
        # Step 5: Handle outliers and transformations
        self.handle_outliers_and_transformations()
        
        # Generate report
        self.generate_cleaning_report()
        
        # Save cleaned data
        self.save_cleaned_data()
        
        return self.df

def main():
    """Main function to run the data cleaning process"""
    print("üè† DATA CLEANING & PREPROCESSING - DANANG REAL ESTATE")
    print("="*60)
    
    # Initialize cleaner
    cleaner = DanangRealEstateCleaner("../../../FinalReport/data.db")
    
    # Run complete cleaning process
    cleaned_df = cleaner.run_complete_cleaning()
    
    print("\nüéâ Qu√° tr√¨nh Data Cleaning & Preprocessing ƒë√£ ho√†n th√†nh!")
    return cleaned_df

if __name__ == "__main__":
    cleaned_data = main() 